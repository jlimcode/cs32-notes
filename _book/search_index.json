[["index.html", "Computer Science 32: Data Structures 1 Introduction", " Computer Science 32: Data Structures Jason Lim 2021-06-03 1 Introduction These are Jasons CS32 notes from Spring quarter 2021. The class was taught by the legendary David A. Smallberg. That is all. "],["week-1-wednesday-pre-lecture.html", "2 Week 1 Wednesday Pre-Lecture 2.1 Why we dont write public data members 2.2 const Member Functions 2.3 Alternate Constructor Stucture 2.4 Order of Construction 2.5 Separate Compilation", " 2 Week 1 Wednesday Pre-Lecture 2.1 Why we dont write public data members People could change your data when they shouldnt It makes it difficult to change the implementation without changing the interface 2.2 const Member Functions When youre designing the class, you should consider which functions will and wont modify the underlying function. Mark those functions const to promise they wont change anything. 2.3 Alternate Constructor Stucture Remember from CS31: Circle::Circle(double x, double y, double r) : m_x(x), m_y(y), m_r(r) { // you can still do stuff in the constructor body here if (r &lt; 0) { cout &lt;&lt; &quot;bad radius&quot;; exit(-1); } } 2.4 Order of Construction havent learned this yet Construct the data members This consults the member initialization list If a data member is not listed in the member initialization list: If its a builtin type, its left uninitialized If its a class type, the classs default constructor is called (so it wont compile if this constructor doesnt exist) Sometimes, the order in which the data members are initialized matters. The canonical order should be the order in which they are declared in the class declaration. This should (ideally) match with the order of the members in the member initialization list. Execute the body of the constructor 2.5 Separate Compilation When were working with large programs, we sometimes want to make small changes without recompiling the whole thing. Thus, we compile components separately and then link them together. This leads to our system of our headers: we put all the declarations in one place. We use: #include &quot;Circle.h&quot; to put all the code into our .cpp file and allow the different functions/classes to be used. There are two main steps of compilation: 1. Translating all your .cpp files into machine code. (.cpp -&gt; .o) 1. This includes lists of names it defines and names it needs 2. Then all the lists are matched up and files are linked together so that every name is defined. It also goes into the library to find what it needs. 1. Must have just one main() routine 2. Nothing can be defined twice (dont put definitions in the header files, these will get #include-d in multiple places) 2.5.1 Header File Include Practices Just a general principle: if your code in a particular file needs something, just include it (theyre protected from multiple inclusion), even if it includes something that already has it. This is just a good habit in the case that other files change. Dont do using namespace std; in your header files (conflicting names and forcing to specify namespace names). Another small note is that &lt;cstdlib&gt; includes the exit() function that Smallberg uses. #include &quot;myfile.h&quot; // specify user-written declaration file // the name will be treated as a path #include &lt;iostream&gt; // standard c++ libraries use this convention "],["week-1-wednesday-lecture.html", "3 Week 1 Wednesday Lecture 3.1 Constants, pointers, and constant pointers 3.2 Default Constructors 3.3 new and Variable Lifecycle", " 3 Week 1 Wednesday Lecture const to the left generally does nothing. Unless it denotes the return of a pointer to a value you cant modify like const Foo * h; in a function declaration (called like obj.h()). You cant do obj.h()-&gt;modify(); (not marked const function) because it modifies the object at end of ptr. 3.1 Constants, pointers, and constant pointers const Foo * h(const double * p) const; return pointer to const parameter is const ptr but you can modify the thing at the end of the arrow this ptr is a constant obj Pointers to int cant be pointed at const int. Because the pointer records whether or not it can change the thing it points at. However, if you declare a const int *, you can point it at either an int or a const int. If it points at a normal int, you still cant modify. const int * pi can still be pointed at different things, so the pointer itself is not const perse. const int * const cpi = &amp;ci; is something that you cant repoint, and it points to a const object. What does const mean to left and right of star? - left of star refers to thing it points to - right of star refers to the name of the thing were declaring int&amp; ri = i; binds reference to some kind of int (generally as param, not declaration) - makes ri another name for i - cant make ri refer to any other int later - so basically like a constant pointer - except you can ri = 10; just like with i 3.2 Default Constructors With no default constructor, you cant make a built-in array of those objects. You can make an array of pointers to objects without default constructors. It can be dumb to have default. constructor called 800 times to do Blah a[800]; // is this better? Blah * bpa[1000]; int nBlahs = 0; // then later... pba[nBlahs] = new Blah(x, y); nBlahs++; Conclusion: dont have a default constructor if it doesnt make sense. 3.3 new and Variable Lifecycle usage of new is based on lifetime of object local variables, automatic, on the stack, has lifetime of function global variables, (outside of any function), has lifetime of program dynamically allocated variables, on the heap, created using new, return a pointer to place on heap only go away when you explicitly call delete delete takes a pointer to the object you want to delete the value of the pointer doesnt change, dangling pointer, undefined behavior to follow pointer undefined behavior to call delete again if you return a pointer that pointed to a local object the local object gets destroyed so a dangling pointer is returned you dont use delete on pointers to local variables "],["week-2-monday-lecture.html", "4 Week 2 Monday Lecture 4.1 Separate Compilation Issues 4.2 Example Project 4.3 Include Guard Rules 4.4 Pointer Example 4.5 Incomplete Type Declaration 4.6 Resource Management", " 4 Week 2 Monday Lecture 4.1 Separate Compilation Issues For each source file (.cpp) in a project, compiler produces object file (.o or .obj) containing: - the machine language translation of the code - storage for global objects (like std::cout) - a list of global names defined (aka implemented) by this object file - a list of global names used in this file that need a definition somewhere Then, the linker brings all the objects together with object files from libraries to make an executable file. The linker needs these rules to be upheld: - Nothing can be defined more than once - Every need must be satisfied by some definition - There must be exactly one main routine Simple rule for usage: &gt; If you want to use a class type, include the appropriate header 4.2 Example Project Point.h // some include guards: // (still the only portable way to protect) #ifdef POINT_INCLUDED #define POINT_INCLUDED // so it will only define once, as desired class Point { //... }; #endif // POINT_INCLUDED Circle.h #include &quot;Point.h&quot; class Circle { //... private: Point m_center; double m_radius; }; main.cpp #include &quot;Circle.h&quot; // shouldn&#39;t have to include &quot;Point.h&quot; if not being used directly, but also should require it if it is being used. // you shouldn&#39;t have to know if Circle is implemented with Point or not //if I #include &quot;Point.h&quot; at this point, now we&#39;ll get a complication error because Point will get declared twice (not with the include guards I included) int main() { Circle c(-2, 5, 10); return 0; } 4.3 Include Guard Rules Make the symbol youre defining to be unique Unique names typically include filename Dont write anything significant outside the #ifndef block 4.4 Pointer Example This works with the Incomplete Type Declaration section and offers an illustrative example. Student.h #ifndef STUDENT_INCLUDED #define STUDENT_INCLUDED //can&#39;t include Course here and Student in Course.h because that&#39;s a circular dependency // compilers need to know how big the object will be // this will be 10 times as big as a Course pointer // but C++ already knows how big any pointer is (they&#39;re all 4 bytes) // now you can just use an incomplete declaration to break circular dependency and speed up compilation class Course; class Student { public: void enroll(Course* cp); private: Course* m_studyList[10]; }; #endif // !STUDENT_INCLUDED Course.h #ifndef COURSE_INCLUDED #define COURSE_INCLUDED class Student; // breaking circular dependency class Course { public: int units() const; private: Student* m_roster[1000]; }; #endif // !COURSE_INCLUDED main.cpp #include &quot;Student.h&quot; #include &quot;Course.h&quot; void f(Student* s, Course* cp) { s-&gt;enroll(cp); } 4.5 Incomplete Type Declaration C++ allows for declarations of a class that dont give any other information. You can do this as many times as you like and still give a full declaration later. class A; // ... class A; // ... class A { //... }; // ... class A; You can even keep giving incomplete declarations after the complete one! You can use an incomplete declaration anytime youre just using a reference or pointer to the class type (C++ already knows the size). But if you have a data member of that type, you need to have the full declaration to see the full size. In general: &gt; If the file Foo.h defines the class Foo, when does another file require you to say &gt; cpp &gt; #include \"Foo.h\" &gt; &gt; and when can you instead simply provide the incomplete type declaration &gt; cpp &gt; class Foo; &gt; &gt; &gt; You have to #include the header file defining a class when &gt; * you declare a data member of that class type &gt; * you declare a container (e.g. an array or a vector) of objects of that class type &gt; * you create an object of that class type &gt; * you use a member of that class type class Blah { //... void g(Foo f, Foo&amp; fr, Foo* fp); // just need to say class Foo; //... Foo* m_fp; // just need to say class Foo; Foo* m_fpa[10]; // just need to say class Foo; vector&lt;Foo*&gt; m_fpv; // just need to say class Foo; Foo m_f; // must #include Foo.h Foo m_fa[10]; // must #include Foo.h vector&lt;Foo&gt; m_fv; // must #include Foo.h }; void Blah::g(Foo f, Foo&amp; fr, Foo* fp) { Foo f2(10, 20); // must #include Foo.h f.gleep(); // must #include Foo.h fr.gleep(); // must #include Foo.h fp-&gt;gleep(); // must #include Foo.h } As a result of these rules, you cant have a class B with a data member of class A when class A has a data member of class B. There is infinite recursion here that you should avoid anyway (when the compiler goes to calculate object size it will get an infinite size). 4.6 Resource Management We dont manage infinite resources, so well focus on computer resources that are limited. Were going to focus on memory for this class. Lets imagine that were back in time. When c++ had no standard library. Lets try to write a standard String implementation. void h() { String s(&quot;Hello&quot;); String t; char* p; // ... set p somehow String u(p); } class String { public: String(const char* value); //remember that any string literal is actually a cstring, and that any array is passed as a pointer to the first item String(); private: // Class invariant: // m_text is a pointer to dynamically allocated array of m_len+1 characters // m_len &gt;= 0 // m_len == strlen(m_text) char* m_text; //dynamically allocate so we don&#39;t default to too much or too little memory int m_len; } String::String(const char* value) { m_len = strlen(value); m_text = new char[m_len+1]; strcpy(m_text, value); } String::String() { m_len = 0; m_text = new char[1]; m_text[0] = &#39;\\0&#39;; } Could you massage these into one constructor? String::String(const char* value = &quot;&quot;) { m_len = strlen(value); m_text = new char[m_len+1]; strcpy(m_text, value); } // now you don&#39;t need separate default We decide for empty string, should we just point to array of just null bit, or do we have the nullptr? There are time costs and memory costs for initializing null bits, but its easier to implement. The needs of your users outweigh saving you time as a developer. So the right decision is nullptr. Costly to calculate length, so perhaps we store an integer of length as a data member. Dealing with potential nullptr: String::String(const char* value = &quot;&quot;) { if (value == nullptr) { value = &quot;&quot;; } m_len = strlen(value); m_text = new char[m_len+1]; strcpy(m_text, value); } And we need a destructor, because the default constructor generated for built-in types does essentially nothing. We need to get rid of everything we dynamically allocated. When you dynamically allocate a single object, you can just delete it. If you dynamically allocate an array of class objects, you use the array delete: delete[]. Must pass the pointer to element 0 with this command. String::~String() { delete[] m_text; } When you have a local variable, the destructor is called automatically when you exit the bracket. If you have: struct Employee { String name; double salary; int age; }; void f(int age) { Employee e; e.salary = 12345.6; e.age = age; } The new Employee object we made gets cleaned nicely at the bottom because after the empty default destructor runs, each data member will get destructed by its own specified or built-in destructor. "],["week-2-monday-qa.html", "5 Week 2 Monday Q&amp;A 5.1 Destructor Cycle", " 5 Week 2 Monday Q&amp;A 5.1 Destructor Cycle Run destructor body Perform some action for each data member of an object. If its a class type, the classs destructor is called If its built-in, nothing happens This is dangerous if its a pointer to a dynamically allocated memory object. Because the pointer is built in, it wont do anything and the object in the heap will remain (memory leak). Something else (not covered yet) Note: objects cant contain a data member of a type that has a data member of the original type (infinite recursion in constructors). Smallberg says theres no issue if one of them is a pointer to the other object. Dont have to dynamically allocate array for Project 1 because we are given upper bounds for dimensions. "],["week-2-wednesday-lecture.html", "6 Week 2 Wednesday Lecture 6.1 Copying 6.2 Assignment 6.3 Aliasing", " 6 Week 2 Wednesday Lecture More on resource management. We use our definition of String from last time. 6.1 Copying Consider the situation: void f(String t) { // .... } void h() { String s(&quot;Hello&quot;); f(s); // ... } Here you pass by value. If you dont tell C++ what to do, it will default to just copying each member. So if f() changes the pointer member, we could affect the original object. Another problem, is that at the end of f(), all local variables get deleted, so your pointer in s is now dangling. Even if you dont touch s after, at the end of h() it will try to delete the object at the end of the pointer again, which is undefined behavior. Lets make t have its own copy. We inform the compiler how to copy. We add public: String(const String&amp; other); to the class declaration. And then we define it: String::String(const String&amp; other) { m_len = other.m_len; m_text = new char[m_len + 1]; strcpy(m_text, other.m_text); } This is called the copy constructor, and C++ will use it by default when copying the object. Its illegal to pass by value to the copy constructor (infinite recursion). You are allowed to have your copy constructor modify the original object. Ways to make a copy: String x(s); String x = s; // and passing by value to a function Note that you can talk about the private members of any String in the copy constructor (and any member function). They did this just to make it way easier to write copy constructors. 6.2 Assignment Some misconceptions: s= t; // assignment String x(s); // copy construction String x = s; // copy construction, NOT assignment Consider: void h() { String s(&quot;Hello&quot;); f(s); String u(&quot;Wow&quot;); u = s; // how do we deal with assignment? } The default is to just assign each data member. Pointer will point to the same place in memory as the original - which is a problem, and there will be a memory leak in the original value of u. u = s; // is shorthand for: u.operator=(s); Which we implement as: public: void operator=(const String&amp; rhs); // not quite the current convention in the class declaration. And then we define it: void String::operator=(const String&amp; rhs) { delete m_text; // not quite right, we&#39;ll fix it later m_len = rhs.m_len; m_text = new char[m_len + 1]; strcpy(m_text, rhs.m_text); } If we want this special behavior of built in types: int k = 3; int n = 5; int m; m = k = n; we modify our operator accordingly (return new value of LHS from an assignment statement). String String::operator=(const String&amp; rhs) { delete m_text; // not quite right, we&#39;ll fix it later m_len = rhs.m_len; m_text = new char[m_len + 1]; strcpy(m_text, rhs.m_text); return *this; // return what the pointer points to // but this implementation is a bit inefficient } // here&#39;s the fix: String&amp; String::operator=(const String&amp; rhs) { delete m_text; // not quite right, we&#39;ll fix it later m_len = rhs.m_len; m_text = new char[m_len + 1]; strcpy(m_text, rhs.m_text); return *this; // return a reference to original } But self-assignment could present a problem when you delete yourself before getting the value. Doing strcpy to itself is undefined behavior, probably keep reading and storing bytes until it gets to \\0. Well revisit our function again: String&amp; String::operator=(const String&amp; rhs) { if (this != &amp;rhs) { delete m_text; m_len = rhs.m_len; m_text = new char[m_len + 1]; strcpy(m_text, rhs.m_text); } return *this; // return a reference to original } This is the classic way to write an assignment operator. But now there is a modern way. Note: our check for being the same is different than *this != rhs, because this compares the value of two strings. This is nice because it skips the work if it already has the right value, but it can be hard to check the equality of string value. Balance the cost between reassignment and checking if the value is the same. Generally we compare the pointers, not the values of the string. Another note: technically you could replace the assignment operator definition with the destructor and copy constructor. But this is hard and uses stuff we dont know yet. The old way to avoid code duplication was to write a private helper function. Heres another problem: in our current implementation of the assignment operator, we do serious damage to the left-hand side before we know that our operation will succeed. This can lead to undefined behavior later in the program. The following fix is just a cleaner, modern way to write assignment operators. class String { public: //... void swap(String&amp; other); //... private: //... }; void String::swap(String&amp; other) { // simple operations like this can&#39;t throw exceptions // I decided to implement this more concretely int temp_len = m_len; m_len = other.m_len other.m_len = temp_len; char* temp_textptr = m_text; m_text = other.m_text; other.m_text = temp_textptr; // and then local temp variables are cleaned up } String&amp; String::operator=(const String&amp; rhs) { if (this != &amp;rhs) { String temp(rhs); // will fail here if there isn&#39;t memory swap(temp); // so lhs is protected // note that the above is this-&gt;swap(temp); } return *this; // return a reference to original } The above solution also leverages the code written in the copy constructor to prevent code duplication. 6.3 Aliasing An alias is two names for the same object. Ask yourself: is my code correct if these names refer to the same value? Example: void transfer(Account&amp; from, Account&amp; to, double amt) { if (amt &gt; from.balance()) { //... error } else { from.debit(amt); to.credit(amt); } } Here there is an issue of aliasing. When you have two references to the same type, aliasing might occur. Nothing catastrophic happens here, but it treats a self-to-self transfer like a standard transfer, so it will throw errors, incur fees, etc. Make sure your implementation does the right thing in the case of aliasing. void transfer(Account&amp; from, Account&amp; to, double amt) { if (&amp;from != &amp;to) { if (amt &gt; from.balance()) { //... error } else { from.debit(amt); to.credit(amt); } } } "],["week-2-wednesday-qa.html", "7 Week 2 Wednesday Q&amp;A", " 7 Week 2 Wednesday Q&amp;A When a function runs but cant do its job, the best thing it can do is return without changing anything. This is motivation for our swap() approach to assignment operator. Sometimes copying a resource needs more thought than just copy or dont copy. You can address this in your override (think about a network connection). I watched this lecture to 13:15. "],["week-3-monday-lecture.html", "8 Week 3 Monday Lecture 8.1 Introduction to Linked Lists 8.2 First Link List Implementation 8.3 Linked List Iteration 8.4 Finding a Specific value 8.5 Getting Rid of a Node", " 8 Week 3 Monday Lecture 8.1 Introduction to Linked Lists So far all weve seen in terms of data types are arrays (fixed size or dynamically allocated). Technically dynamically allocated is called dynamically allocate fixed size array because the size cant be changed after creation. We can create a resizable array by redefining our insert function to allocate more storage if the existing array runs out of room. Called a vector in the c++ standard library. In an array, its computationally cheap to find an item, or put a new item at the end. Inserting is more expensive because you have to move everything over (the closer to the beginning you insert, the more costly it is). You would need to insert when you want to keep the items in a particular ordering. Goal: represent a collection of values for which inserting and removing items preserves the order of the other items, but is efficient even if the insertions are not at the end. What if we make the elements of our collection not right after each other in memory. For each element, you need the data item and where the next one is. This structure is called a link list. 8.2 First Link List Implementation struct Node { int value; Node* next; // must be a pointer to avoid recursive size equation }; Node* head; 8.3 Linked List Iteration Lets assume we already have the linked list set up. Lets write code that tries to visit each node and print. while(head != nullptr) { std::cout &lt;&lt; head-&gt;value &lt;&lt; std::endl; head = head-&gt;next; } // MAJOR MEMORY LEAK!! Weve cut ourselves off from all the nodes in our program. We shouldnt change the head pointer! for(Node* p = head; p != nullptr; p = p-&gt;next) std::cout &lt;&lt; p-&gt;value &lt;&lt; std::endl; // this one works General rule: whenever you write p-&gt;_____, - make sure p is not uninitialized - make sure p is not nullptr So for this, make sure you always initialize head and all values of next with valid pointers. 8.4 Finding a Specific value Finding first occurrence of 18 in our linked list. Node* p; for(p = head; p-&gt;value != 18; p=p-&gt;next) ; //in c++ this is the empty statement, which does nothing This doesnt work because it assumes an 18 will be found. It also doesnt check for p being the nullptr. p could be nullptr from either head or p-&gt;next Node* p; for(p = head; p != nullptr &amp;&amp; p-&gt;value != 18; p=p-&gt;next) ; //note the order of conditions to avoid evaluation with nullptr Insert a 54 after the 18 in the list, if present: Node* p; for(p = head; p != nullptr &amp;&amp; p-&gt;value != 18; p=p-&gt;next) ; if(p != nullptr) { Node* newGuy = new Node; newGuy-&gt;value = 54; newGuy-&gt;next = p-&gt;next; p-&gt;next = newGuy; } Note on order: cant go wrong if you set the fields of the newly allocated node first. 8.5 Getting Rid of a Node Get rid of the node after the 18 node: Node* p; for(p = head; p != nullptr &amp;&amp; p-&gt;value != 18; p=p-&gt;next) ; if(p != nullptr) { Node* toBeDeleted = p-&gt;next; p-&gt;next = p-&gt;next-&gt;next; // or toBeDeleted-&gt;next; delete toBeDeleted; } Get rid of the first occurrence of 18 (somewhat trickier because you cant trace a pointer backwards): You could do it in two loops by finding 18 and then the node pointing to 18. Or you can do it in one loop with a lagging pointer that follows the node youre checking. Tips: - check how the list works when the area of interest is - at the front - at the back - in the middle - check one-element list What if our 18 is at the end of the list, and we want to insert 54 after? if(p != nullptr) { Node* newGuy = new Node; newGuy-&gt;value = 54; newGuy-&gt;next = p-&gt;next; //nullptr p-&gt;next = newGuy; } Here, our previous implementation works. However, if were trying to delete a specific item from the very front of the list, the general algorithm doesnt work. We rewrite to handle this special case: head = p-&gt;next; delete p; If youre doing a lot at the tail of the list, you might want to keep a pointer to the tail. Adding an item to the end is simple: Node* newEnd = new Node; newEnd-&gt;value = 87; newEnd-&gt;next = nullptr; tail-&gt;next = newEnd; tail = newEnd; Empty list: both head and tail will be nullptr, so this is a special case. You could also address the deleting a specific node problem by storing two pointers in each node, one pointing to the previous node and one pointing to the next node. This is called a doubly-linked list. "],["week-3-wednesday-lecture.html", "9 Week 3 Wednesday Lecture 9.1 Stacks in c++ 9.2 Queues in c++ 9.3 Motivating Example for Stacks 9.4 Implementing Stacks with Arrays/Lists", " 9 Week 3 Wednesday Lecture Data structure where you can only add or remove items at one end of the structure is called a stack. Using this structures tells your reader exactly what youre using the list-type structure for. You can push to the end to add, pop from the end to remove. You can also look at the top item. And check if the stack is empty. Some libraries will give you functions to look at any member and check how many items there are. 9.1 Stacks in c++ In c++ you use #include &lt;stack&gt; to get std::stack in your code. Looking at the top of an empty stack or trying to pop from an empty stack is undefined behavior in c++. #include &lt;stack&gt; using namespace std; stack&lt;int&gt; s; s.push(10); s.push(20); cout &lt;&lt; s.top() &lt;&lt; endl; s.pop() // no return if (s.empty()) { cout &lt;&lt; &quot;Stack is empty!&quot; &lt;&lt; endl; } else { cout &lt;&lt; s.top() &lt;&lt; endl; cout &lt;&lt; s.size() &lt;&lt; endl; } 9.2 Queues in c++ If we look at a similar data type with one side where you add new elements and one side where you remove elements. This is called a queue. The add side is called the tail or the back, the remove/view side is called the head or front. In general, we have the operations enqueue to add to back of queue, dequeue to remove from the front of the queue, look at the front end of the queue, and check if the queue is empty. Some libraries will let you view the back item, view any item, and ask how many items are in the queue. #include &lt;queue&gt; using namespace std; queue&lt;int&gt; q; q.push(10); q.push(20); cout &lt;&lt; q.front() &lt;&lt; endl; q.pop() // no return if (q.empty()) { cout &lt;&lt; &quot;Queue is empty!&quot; &lt;&lt; endl; } else { cout &lt;&lt; q.size() &lt;&lt; endl; cout &lt;&lt; q.back() &lt;&lt; endl; } Once again trying to view the front, back or pop from an empty queue is undefined behavior. 9.3 Motivating Example for Stacks Prefix notation: \\(f(x,y,x)\\) or add(sub(8, div(6,2)), 1) Infix notation: this is our standard mathematical syntax \\(8-6/2+1\\) but it doesnt give the full context so we must have rules of precedence. Postfix notation: 6 6 2 / - 1 + which is once again unambiguous. In calculator history, Texas Instruments created a calculator that you could enter your calculations in standard infix notation. But this took up code on the chip so they couldnt add other functionality beyond square root. HP took a different approach and made a calculator that could do many different calculations, but you had to enter your calculations in postfix notation. Calculating postfix with a stack: If its a number, put it on the stack If its an operator, pop off the number of operands off the stack. Then calculate and push the result back onto the stack Converting infix to postfix with a stack: If you get an operand, append it to the result sequence Else if the current it is (, push it onto the stack Else if the current item is ), pop operators off the stack, appending them to the result sequence until you pop at (, which you dont append If the current item is an operator: If the current stack is empty, push the current operator onto the stack Else if the top of the stack is (, push the current operator onto the top of the stack Else if the current operator has precedence strictly greater than the operator on the top of the stack, push the current operator unto the stack If it doesnt have higher precedence, pop the top operator from the stack and append it to the result sequence Then check again and repeat if necessary At the end of the input sequence, pop each operator off the stack and append it to the result sequence. 9.4 Implementing Stacks with Arrays/Lists Using a pointer for array item. Points to next available space. Be careful not to pop or view top from an empty stack. Linked list will start at the top with a single linked list, where it will add and pop from. Dont pop or view top from an empty stack. "],["week-4-monday-lecture.html", "10 Week 4 Monday Lecture 10.1 Implementing Queue with an Array 10.2 Polymorphism 10.3 Implementation of Polymorphism 10.4 Static and Dynamic Binding", " 10 Week 4 Monday Lecture 10.1 Implementing Queue with an Array Your head and tail are two pointers that indicate the front and end of the queue in the array. Popping from the front moves the head back and enqueueing to the back adds elements and shifts the tail pointer. This continues until you attempt to enqueue and reach the end of your array. Do you give up? No because there could be spots in the array freed by popping. Do you shift everything over to give more space for enqueueing at the end of the array? No because this is costly copying. So the clever idea is to wrap around to the beginning and put the 101th element in item 0s spot. Then when you pop past the 100th element, you move it back to the beginning. Then you can wrap around and easily use all 100 spaces in your array for the queue. Were treating linear array memory like its a circle. This can be called ring buffer or circular array. Putting the tail pointer one past the last item in the queue, you get tail == head when the queue is empty or if the queue is full. Then you should probably keep the size so you know its empty if size == 0, and full if size==100. If you have an expandable array, make sure you copy head into 0, tail into 100 rather than their original indexes because those wont wrap correctly. 10.2 Polymorphism This is a general programming language concept rather than a c++ specific concept or a data structure. In c++ you can put objects of different types into a collection, but you have to be careful about it so your program can check stuff at compile time. Note: Circle* ca[100]; // create an array of pointers to circles // this avoids creating 100 circles along // with the array Polymorphic implementation class Shape { //base class public: void move(double xnew, double ynew); void draw() const; private: double m_x; double m_y; // these properties shared by all shapes }; class Circle : public Shape { //derived class public: void move(double xnew, double ynew); void draw() const; private: double m_x; double m_y; double m_r; }; class Rectangle : public Shape { //derived class public: void move(double xnew, double ynew); void draw() const; private: double m_x; double m_y; double m_dx; double m_dy; }; Shape* pic[100]; pic[0] = new Circle; pic[1] = new Rectangle; Every object of a derived type has an object of the base type embedded inside it. So it will have everything a Shape object plus whatever else you add. If you give a pointer to a Circle but you need a pointer to Shape, the compiler will do an automatic conversion to allow you to get the right kind of pointer. Compilers optimize this conversion by putting the start of the base object right up at the top of the derived object. That way to convert between pointers you simply add 0 (just return the pointer as is). for (size_t i = 0; i &lt; MAX_SIZE; i++) { pic[i].draw(); //this works now through inheritance } 10.3 Implementation of Polymorphism Shape::move(double xnew, double ynew) { m_x = xnew; y_x = ynew; } // this will work for all shapes Drawing will require different functions for the different kinds of shapes. Because you added these function declarations to the class declarations of the derived types, the compiler will look for their separate definitions. void Circle::draw() const { //draw a circle with m_r at x,y } This is called an override for the draw() function. But because you gave Shape a draw method too, you need to define it. But what makes sense to draw? Well implement now and fix it later. void Shape::draw() const { //draw some vague cloud at x,y } 10.4 Static and Dynamic Binding Static binding vs. dynamic binding: putting the code together with the function call at compile time vs. putting the function body to the call at runtime. We cannot statically bind draw() in this example. Other languages will always just dynamically bind, but c++ wanted the performance boost of statically binding by choice. The default is actually static binding, so you need to indicate if you want dynamic. The consequences for our program are that move() and draw() will always call Shapes version because they have been statically bound during compile. This is fine for move() but not for draw(). Heres how we indicate that we want dynamic. class Shape { //base class public: void move(double xnew, double ynew); virtual void draw() const; // don&#39;t have to repeat is subclasses, but // you can just to help readability }; If you let a method be statically bound, then you dont have to write an override in subclass because it will never get called. But here youre making a prediction about the future that youre never going to want to override the method in any future subclasses. class WarningSymbol : public Shape { void move(double xnew, double ynew); }; void WarningSymbol::move(double xnew, double ynew) { Shape::move(xnew, ynew); // call the correct move function // then do something else // like flashing } void f(Shape&amp; x) { x.move(10, 20); } WarningSymbol ws; ws.move(5, 15); //this will work f(ws); //this calls the wrong move //because statically bound So when you want to override, you have to specify virtual. "],["week-4-wednesday.html", "11 Week 4 Wednesday 11.1 Dynamic Lookup 11.2 Abstract Classes 11.3 Multiple Inheritance?", " 11 Week 4 Wednesday 11.1 Dynamic Lookup Some driver code to illustrate how the compiler matches the right function bodies with a seemingly ambiguous function call/ Shape* sp; if (someCondition) { sp = new Shape; } else { sp = new Rectangle; } sp-&gt;draw(); How do we call the right draw? The C (naive-ish) way: include an integer code in Shape that specifies what type of shape it is. Then when you call draw(), the function checks the integer code of the object and calls the correct version of itself. This is bad because it requires complete recompilation of everything involving Shape every time you want to add a new class that implements Shape. There will need to be a new integer code and all function calls to draw() have to recognize it. This recompilation is costly and should be avoided. The c++ way: compiler sets up a table for Shape called a virtual table of vtbl. Has an entry for each virtual function of the Shape type. Tells the linker to put pointers to Shapes draw and move functions in the table. Rectangle will also have a virtual table for every virtual function in the class (move, draw, diag). The ones already declared in Shape will be in the same slots in Rectangles virtual table as in Shapes. Diag will have a pointer to Rectangles function. Draw will point to Rectangles draw() function, and the move will point to Shapes move function. Compiler knows draw() is in slot #1 (arbitrary) for every class. Compiler gives an extra pointer called the virtual pointer for any object with virtual methods, vfptr in VS. In the constructor for rectangle, make a pointer in the Shape subset object to Rectangles virtual table. So the machine code is &quot;call the function at&quot; sp-&gt;vptr[1]; // the function in the second slot of //whatever virtual table you have Note that this says nothing about specific derived types. This gives us the flexibility to introduce new derived types of Shape without recompiling our code. 11.2 Abstract Classes Our implementation of Shapes draw function is kinda silly. Do we need it? Right now, yes because the compiler needs to guarantee that every Shape pointer object will lead to something drawable. But if I say that Im not going to specify a draw function for Shape but that every derived class will have one, that may work. You want to set the pointer in the lookup table to nullptr. Heres how you do it: class Shape { virtual void move(double xnew, double ynew); virtual void draw() const = 0; //no new keywords lol // called a &quot;pure virtual function&quot; double m_x; double m_y; } Consequences: you cant make objects of the Shape type. So none of these: Shape* sp = new Shape; Shape s; But pointers to Shape with other things in there are fine. Then Shape is called an abstract base class, sometimes called ABC. If you dont declare a draw function in a subclass, you wont be allowed to instantiate that class either. 11.3 Multiple Inheritance? class Shape { //... }; class Polygon: public Shape { ~Polygon(); Node* head; } Shape just had ints, so we didnt need a destructor, but Polygon is a linked list so we need to clean it up. Shape* sp; if (someCondition) { sp = new Polygon; } else { sp = new OtherShape; } delete sp; //which destructor to call? You need your destructor to be virtual, but Shape doesnt declare a destructor anywhere. And we cant default to virtual for every class, because thats slow. So we declare Shapes destructor. So class Shape { //... virtual ~Shape(); }; class Polygon: public Shape { virtual ~Polygon(); Node* head; } But what if Shape is abstract, then theres never a Shape object to destroy. But turns out you still need that Shape destructor. Recall the destructor cycle: Execute the body of the constructor Destroy the data members Destroy the base part So deleting a Polygon will call Shapes destructor. So we have to implement it. Even if all our subclasses dont have destructors, the Shape destructor still gets called. So we give the somewhat lame definition: Shape::~Shape() {} So just write destructors for anything that may be a base class. Avoids recompilation later. Now lets review the constructor cycle. Its the destructor in reverse! Construction: 1. Construct the base part 2. Construct the data members 3. Execute the body of the constructor Destruction: 1. Execute the body of the constructor 2. Destroy the data members 3. Destroy the base part Heres our setup: class Shape { public: Shape(double x, double y); virtual ~Shape(); private: double m_x; double m_y; }; Shape::Shape(double x, double y) : m_x(x), m_y(y) {} class Circle : public Shape { public: Circle(double r, double x, double y); Circle(double r); private: double m_r; } The following code doesnt compile: Circle::Circle(double r, double x, double y) : m_x(x), m_y(y), m_r(r) {} Because were trying to access m_x and m_y which arent members that Circle can access, theyre private to Shape. So we should initialize those with Shape. (First step of construction is construct the base part). Circle::Circle(double r, double x, double y) : Shape(x, y), m_r(r) {} An additional piece of information is given to the Shape constructor that points to Circles virtual table. This is how it knows its a Circle. What if we have Circle::Circle(double r, double x, double y) : m_r(r) { if (r&lt;=0) { //error handling } } Then the compiler looks for a default constructor for Shape, but since there is none this is a compilation error. And our other Circle constructor looks like: Circle::Circle(double r) : Shape(0, 0), m_r(r) { if (r&lt;=0) { //error handling } } } "],["week-5-monday-lecture.html", "12 Week 5 Monday Lecture 12.1 Motivating Recursion 12.2 Introduction to Recursion 12.3 Implementing the Merge Sort", " 12 Week 5 Monday Lecture 12.1 Motivating Recursion When you have a big problem, you can solve it by breaking it into smaller problems. When the smaller problems are just smaller versions of the big one, then you can use recursion. When you have a lower bound for the size of the job, and each recursive call works with a strictly smaller problem, then the recursive algorithm must terminate. (Sounds like Monotonic Convergence Theorem to me). 12.2 Introduction to Recursion base case(s): path(s) through the function that do not make a recursive call recursive case(s): path(s) through the function that make a recursive call Every recursive call is to solve a strictly smaller problem (getting closer to base case) You must make the recursive leap of faith when you know the base case works, and you assume the function will work for smaller instances of the same problem and just make the recursive step get closer to the base. 12.3 Implementing the Merge Sort Turns out its easier to represent an array segment with the start and the length, rather than the start and the end (end leads to lots of +1 and -1). Then if b is your beginning, e can be the index right past the end, then m = b + e / 2 is the point right past the end position of the first segment. void sort(int a[], int b, int e) { if (e - b &gt;= 2) { int mid = (b + e) / 2; sort(a, b, mid); sort(a, mid, e); merge(a, b, mid, e); } } "],["week-5-wednesday-lecture.html", "13 Week 5 Wednesday Lecture 13.1 Pointers and Arrays 13.2 Infinite Recursion 13.3 Types of Recursive Problems 13.4 Common Mistakes in Recursion 13.5 Templates", " 13 Week 5 Wednesday Lecture 13.1 Pointers and Arrays Important note on array parameters! Pointers are not the same as arrays. However, when you declare a function with an array parameter, all c++ knows is that its a pointer to the array type. You could pass f(int[] a, int n) as f(int* a, int n) and it would work the same. When you pass it in, its just a pointer so you cannot possibly know what the size of the array is. Thus, you need a size parameter that just gets treated as fact. 13.2 Infinite Recursion If you accidentally set up an infinite recursion, your program will eventually crash when you run out of allocated space for local variables. This is different than an infinite loop where no resources are being consumed other than power. 13.3 Types of Recursive Problems Divide and conquer or the first and the rest or the last and the rest. Divide and conquer works well for sorting because you need to view each item more than once. Whereas the other two work for more types of problems like were solving in homework 3. 13.4 Common Mistakes in Recursion We can think of these in mistakes in a proof by induction. Did you do the base case or inductive step incorrectly? Sometimes your inductive step fails for a small \\(n\\) like 1 or 2. Can come up when youre inferring about a larger collection based on the smaller collection. An example mistake: bool has(int a[], int n, int target) { if (a[0] == target) { return true; } return has(a+1, n-1, target); } This wont work, but clearly something is wrong because theres no place it can return false. The only base case is when you match the element, so this seems off as well. Also it looks like the recursive calls all decrease n, but there doesnt appear to be a lower bound in the function. Heres the fix: bool has(int a[], int n, int target) { if (n &lt;= 0) { return false; } if (a[0] == target) { return true; } return has(a+1, n-1, target); } 13.5 Templates Were back on a computer language type topic. A way to make your code writing more efficient if you have a language that can support this feature. Heres the type of problem were trying to solve: int minimum(int a, int b) { if (a &lt; b) return a; else return b; } double minimum(double a, double b) { if (a &lt; b) return a; else return b; } These two implement the same algorithm for different types. Note that the underlying machine code will actually be different. Were just telling the compiler how to make machine code matching the template of this algorithm. New keyword: template template&lt;typename T&gt; T minimum(T a, T b) { if (a &lt; b) return a; else return b; } The compiler generates everything at compile time, doesnt consider the template as a function until it is called with typed objects. When the template is called the first time, the compiler generates the code and machine code for the right function. Then this code can be reused in subsequent call. When the template is called with some objects, it generates the code through a process called template argument deduction. 1. The call matches some template 2. The instantiated template must compile 3. The instantiated template must work as intended In template argument deduction, the compiler doesnt consider possible conversions like double to int. All the operators and functions called in the template must be defined for the type passed in. This will also result in a compiler error. Heres an example where the instantiated template doesnt work as intended. int main(int argc, const char** argv) { char ca1[100]; char ca2[100]; cin.getline(ca1, 100); cin.getline(ca2, 100); char * ca3 = minimum(ca1, ca2); return 0; } This will just compare the two char pointers. But thankfully, the compiler will match normal functions defined for the type over templates, so we can define a special version of minimum for cstrings. For matching, the only conversions considered are: - A to A&amp; - A to const A - array of A to A* Note that matching is only performed based on the parameter types, not the return type. "],["week-6-monday-lecture.html", "14 Week 6 Monday Lecture 14.1 More issues with Templates 14.2 Template Classes 14.3 STL 14.4 Vector 14.5 Linked Lists", " 14 Week 6 Monday Lecture 14.1 More issues with Templates You dont know if your client will call your function with something that is expensive to copy. So if you dont need to change it, just pass by constant reference in your template. template&lt;typename T&gt; T minimum(const T&amp; a, const T&amp; b) { if (a &lt; b) return a; else return b; } And sometimes you run into some other problems like template&lt;typename T&gt; T sum(const T&amp; a[], int n) { T total = 0; for (size_t i = 0; i &lt; n; i++) { total += a[k]; } return total; } This works really nicely for doubles and ints, but not strings because the initial declaration doesnt work. You cant say string total = 0; Cant use default constructor, works for strings but built in types dont have default constructors. But the c++ people realized that there was no issue if they made it allowed for built-in types. So now double() can be called to get 0. Same exists for char, bool, etc. You get something analogous to 0. 14.2 Template Classes If you write a class that you want to work for many types, and all you would have to do to re-implement it is change some type names, then you can use a template. template&lt;typename T&gt; class Stack { public: Stack(); void push(const T&amp; x); void pop(); T top() const; int size() const; private: T m_data[100]; int m_top; }; Then you put template&lt;typename T&gt; over every member function definition. template&lt;typename T&gt; void Stack&lt;T&gt;::Stack() : m_top(0) {} You put T in the classname too (the alias name you choose for type). You only instantiate the member functions you use. So you can have a template that wouldnt have all the functions work, you just cant use any of the ones that wont work for that particular type. ex. you can push a double to an int stack. Because were done matching at this point, we know what type T ought to be, so we are allowed to pass doubles to this int function. 14.3 STL The c++ people decided that some of the library things needed to be standardized. Someone had already started to create some standard libraries. But HP engineers created their own standard libraries called STL for Standard Template Library. It was so clever that c++ decided to make it the standard. STL includes all of the data structures weve seen so far. 14.4 Vector #include vector using namespace std; vector&lt;int&gt; vi; vi.push_back(10); vi.push_back(20); vi.push_back(30); vi.size(); vi.front(); vi.back(); for (size_t i = 0; i &lt; vi.size(); i++) { cout &lt;&lt; vi[i]; // overloaded square brackets } vi.pop_back(); vi.at(1) = 60; vi.at(3) = 70; //throws an exception (bounds checking) vector&lt;double&gt; vd(10); // vd.size() is 10, each element is 0.0 vector&lt;string&gt; vs(10, &quot;Hello&quot;); // vs.size() is 10, each element is &quot;Hello&quot; int a[5] = {10, 20, 30, 40, 50}; vector&lt;int&gt; vx(a, a+5); // vx.size() is 5, each element is a copy of corresponding in `a` // you pass a pointer to first and pointer right past last element Common mistake: vi[0] = 10; //undefined!!, might not be allocated vi.push_back(10); //correct Note: clang and g++ use size and capacity as integers. Microsoft with Visual c++ uses pointers. This small difference would really only come up in a debugger because they work the same. Note: as you add objects to the vector, the items can move because we need to make new storage thats bigger. So if youre working with pointers, this could be problematic. This concept is called invalidation. Dont traverse a vector with pointers while youre modifying it. 14.5 Linked Lists Note: In general, STL will only implement a method if it will be efficient #include &lt;list&gt; using namespace std; list&lt;int&gt; li; li.push_back(20); li.push_front(10); li.size(); li.front(); li.back(); li.push_front(40); li.pop_front(); //no square bracket operator! li.begin(); //iterator to beginning li.end(); //iterator pointing to right past end //if list is empty, li.end() == li.begin() //STL doesn&#39;t give you nodes or let you look at them //instead you get something like a pointer, but an iterator for (list&lt;int&gt;::iterator = li.begin(); p != li.end(); p++) { // ^^ nested type (must be public) cout &lt;&lt; *p &lt;&lt; endl; } Iterators overloaded some syntax like *p to get the value and p++ moves to the next element. Another fun thing (copy from lists to vectors): list&lt;string&gt; vs(ls.begin(), ls.end()); You can also do: list&lt;int&gt;::iterator p = li.end(); p--; p--; //p-=2 doesn&#39;t compile Now youre looking at the 2nd to last element. Then: //inserts at our location p list&lt;int&gt;::iterator q = li.insert(p, 40); //q will point to location of 40, p will point right after it You can also erase: list&lt;int&gt;::iterator q = li.erase(p); //it&#39;s now undefined to do anything with p //q is now a pointer to the element right after p, you could assign this back to p We also have iterator types for any container type. These have more pointer arithmetic. p += 2; //will be defined for vector::iterators Vector iterators do have insert(p, val) functions, even though it could be inefficient at the beginning of the vector. This insert still returns a new pointer to the place the value was inserted. This is necessary because your items could be in a new place after allocating more space. So typically you do: p = vi.insert(p, 40); After you erase at a point, its undefined to do anything to that iterator. This follows the standard of lists and also you dont know what your pointer will point to, so might as well not exist. "],["week-6-wednesday-stl-and-algorithms.html", "15 Week 6 Wednesday: STL and Algorithms 15.1 Standard Algorithms 15.2 Algorithm Analysis", " 15 Week 6 Wednesday: STL and Algorithms 15.1 Standard Algorithms Weve looked at data types in STL, but there are also algorithms associated with those libraries. The convention in STL is to pass an array as a pointer to the first element and a pointer right past the last element. We return a pointer to the item of interest. If the pointer returned is equal to the pointer just after the last element. Well start with int* find(int* b, int* e, const int&amp; target) { for(; b!= e; b++) { if (*b == target) break; } return b; } First we make it more general by making a template: template&lt;typename Iter, typename T&gt; Iter find(Iter b, Iter e, const T&amp; target) { for(; b!= e; b++) { if (*b == target) break; } return b; } Now it will work with arrays, lists, vectors, integers/cstrings etc. This is very similar to the actual find() in STL. STL algorithms embody very simple loops, mostly just for readability and standardization. Follow a consistent set of conventions that c++ programers are familiar with. You access this with #include &lt;algorithm&gt;. You often find that you need to do something similar to the STL function but a little different. You shouldnt rewrite these. You can pass your own functions to STL to perform more custom operations. Your own functions need to have the right arguments and return types to work. You can also do this with sort. bool hasBetterRecord(const Team&amp; t1, const Team&amp; t2) { if (t1.wins() &gt; t2.wins()) return true; if (t1.wins() &gt; t2.wins()) return false; return t1.ties() &gt; t2.ties(); } int main() { std::vector&lt;Team&gt; league; std::sort(league.begin(), league.end(), hasBetterRecord); } Thats it for STL right now. 15.2 Algorithm Analysis When algorithms were first being shared, there was no good way to compare the performance between algorithms because the speed of each computer is different. Instead we count all of the basic steps that the algorithm requires. Note: for large \\(N\\), the smaller terms of the polynomial become irrelevant. We dont care that much about performance of small \\(N\\) because a computer can do those really quickly anyway. To simplify further, were just looking at the overall growth behavior i.e. the highest exponent of \\(N\\). Theorem: A function \\(f(N)\\) is \\(O(g(n))\\) if there exists \\(N_0\\) and \\(k\\) such that for all \\(N\\geq N_0\\), \\(|f(N)| \\leq k\\cdot g(N)\\). Example: for (int i = 0; i &lt; N; i++) // &lt;=========== O(1) * N = O(N) { c[i] = a[i] * b[i]; // &lt;========= O(1) } for (int i = 0; i &lt; N; i++) // &lt;=========== O(N^2) { a[i] *= 2; for (int j = 0; j &lt; N; j++) // &lt;===== O(N) { d[i][j] = a[i] * c[j]; } } for (int i = 0; i &lt; N; i++) // &lt;=========== O(1+2+....+(N-1)) = O(N^2) { a[i] *= 2; for (int j = 0; j &lt; i; j++) // &lt;===== O(i) { d[i][j] = a[i] * c[j]; } } The last two are treated basically the same even though the second is twice as fast as the first. We ignore constant of proportionality for this level of analysis. Heres a comparison of our growth rates. The classic method of matrix multiplication has a high polynomial growth rate. You can also have \\(O(2^N)\\) algorithms which are really bad. This of generating all the possible sets of items in a set. "],["week-7-monday-lecture.html", "16 Week 7 Monday Lecture 16.1 Applications of Algorithm Analysis: Sorting", " 16 Week 7 Monday Lecture 16.1 Applications of Algorithm Analysis: Sorting One way to sort: take smallest value and put it at first, then look for the next smallest and put it in its place. (Also works for largest value) To calculate the efficiency, roughly count the number of times that elements are compared. This comes out to \\(O(n^2)\\). You can also look at worst case, best case, average case. For selection sort, every possibility requires the same amount of work. Another algorithm sorts the elements adjacent against each other as it goes through. Each time you go through swapping, you can stop looking at elements that are in their final correct position (max at end etc). Once no swaps occur, everything is in the right place. This is called bubble sort. This has best case \\(O(n)\\) if the array is already sorted. In the worst case, we have to do every step so thats \\(O(n^2)\\). The average case is still \\(O(n^2)\\) but with a smaller constant of proportionality. Think of being dealt a hand in poker, and each card you get you insert into your hand in the right place. This is called insertion sort. On average you look at half the items that come before the item in question in the array. This is also \\(O(n^2)\\) but has a lower constant of proportionality than bubble sort on average. Best case is \\(O(n)\\). Say you have an array where no item is more than 3 items way from where it should be (or any bounding constant). Then you know you dont have to look that far to insert each new element. People had an idea to improve the speed of insertion sort by sorting every \\(n\\) elements to get everything into the general ballpark and then doing a final insertion sort which would be linear time. This method is called shell sort (named after the guy who created it). This algorithm is \\(\\approx O(n^{1.5})\\). Weve already encountered the merge sort. The time complexity for this algorithm (when the list is split evenly) is expressed as a recurrence relation \\[T(n) = 2T\\left( \\frac{N}{2} \\right) + O(N)\\] Then we can solve this recurrence relation to get the equation \\[T(N) = O(N\\log_2 N)\\] This will grow faster than linear, but much slower than \\(n^2\\). There is a big difference for larger amounts of data. Well look at another algorithm with \\(N\\log N\\) time. This one is called quicksort. We implemented this before with our separate() function. You keep splitting into two piles where one pile contains all elements greater than every element in the other pile. This works best when you split the array evenly. But for general cases, you dont know where the midpoint is. So picking an array element randomly works pretty well. What if you calculate the median item first, to guarantee efficiency. This doesnt work because it takes too long to find the median (same time as if you had a bad split). You could sample and find the median of the sample (which gets you pretty close). Sample 3 items is the general best. "],["week-7-wednesday-sorting-trees.html", "17 Week 7 Wednesday: Sorting, Trees 17.1 Improving Quicksort 17.2 Trees", " 17 Week 7 Wednesday: Sorting, Trees Note: merge sort takes that same amount of time best case, worst case, etc. 17.1 Improving Quicksort More quicksort: best case is linear. Worst cases are pretty common and include the perfect sorted order or reverse order. These worst cases are \\(O(N^2)\\). quicksort has better constants of proportionality in the general case, so we really want to mitigate the worst cases. If hackers know what sorting algorithm your server is using, they can construct sequences that are the exact worst case and then DDOS you with those. You can avoid this by picking random pivots every once in a while. But sometimes they can reverse engineer your pseudorandom generator. But you can try to use true random pivot picks (from radiation). What if you pick a base case of 9 or fewer items? Then when youre done, your pivots are in the right spot, and each of your items is in the right region. Insertion sort is linear time if theres a constant number of steps that bounds the distance from an item to its final position. Research at one point found that 9 is pretty good cutoff point. Still doesnt address the worst case situations but improves quicksort. We could have quicksort monitor itself, so if the recursion ever gets too deep, we swap over to merge sort. Too deep is around \\(2\\log N\\). This improvement is called introsort because its introspective. This algorithm has worst case \\(O(N\\log N)\\). Most programming libraries will do introsort in their main sorting algorithm. 17.2 Trees Some CS concepts are best represented with trees. One thing is a class hierarchy. Another thing is HTML documents. Trees are made of nodes and edges. A path in the tree is a sequence of edges that connect two nodes. The root is the node with no parents (typically a pointer to the top node). Child nodes have parents. A true tree must have a unique path from each node to every other node. Trees cant have multiple parents nor loops. Sibling nodes have the same parents. A node with no children is called a leaf node. Other nodes are called interior nodes. Depth of a node is how many edges away from the root it is. The height of a tree is the depth of the deepest node. struct Node { string name; vector&lt;Node*&gt; children; }; Node* root; int countNodes(const Node* p) { if (p == nullptr) return 0; int total = 1; for (int k = 0; k &lt; p-&gt;children.size(); k++) { total += countNodes(p-&gt;children[k]) } return total; } You can approach your countNodes function in multiple ways: 1. Go all the way down until the node has no more children. Then you come back up and move to the next child. Then you use a stack. A stack seems to suggest recursion. Note the two base cases: empty tree or leaf node. Note that if were not passed a tree, well either get the wrong answer or infinite recursion. 2. I really expected a breadth-first solution but I guess that comes later lol The takeaway is that trees are very well suited to recursion. What about printing all the nodes of a tree in the proper order with indentation to indicate depth? Elizabeth Charles William George Charlotte Louis Harry Archie Anne Peter Savannah just as an example... To correctly determine the amount of indentation, we need to know something about our depth. We can modify the parameters to pass the depth. You can construct the string as string(2* depth, ' '). You can overload with the additional arguments and simplify the interface. void printTree(const Node* p, int depth) { if (p != nullptr) //you can move this call out { cout &lt;&lt; string(2*depth, &#39; &#39;) &lt;&lt; p-&gt;name &lt;&lt; endl; for (int k = 0; k &lt; p-&gt;children.size(); k++) { printTree(p-&gt;children[k], depth + 1); } } } void printTree(const Node* p) { printTree(p, 0); } Slightly better version if you only intend for one version of the function to be called: void printTree(const Node* p, int depth) { cout &lt;&lt; string(2*depth, &#39; &#39;) &lt;&lt; p-&gt;name &lt;&lt; endl; for (int k = 0; k &lt; p-&gt;children.size(); k++) { printTree(p-&gt;children[k], depth + 1); } } void printTree(const Node* p) { if (p != nullptr) { printTree(p, 0); } } "],["week-8-monday-trees.html", "18 Week 8 Monday: Trees", " 18 Week 8 Monday: Trees We were working with this structure this time: #include &lt;vector&gt; #include &lt;string&gt; struct Node { std::string name; std::vector&lt;Node*&gt; children; }; Node* root; What we did to print before was called a preorder traversal. You process the node before processing the subtrees. The opposite is postorder traversal must process all the subtrees before processing the current node. If we did our printing in postorder, we would get the same output in the opposite order. Early in CS, people didnt really like to use dynamically allocated arrays for children pointers. You can represent every tree by nodes with exactly two possible children, called a binary tree. Lets look at the data structure: struct Node { string name; Node* right; Node* left; }; Note that the right and left subtrees are distinct. So there are 3 possible distinct two node trees and 5 distinction 5 node trees. Doesnt this kinda look like a doubly linked list? Yes, but there are requirements about where the pointers point. Doubly-linked always point back to each other. Trees cant point back (sometimes you have a pointer to the parent just to be helpful, but this is not technically a part of the structure of the tree). You can express the original tree with a binary tree by making all left pointers two first child, all right pointers to siblings. We then call the two pointers the oldest child pointer and younger sibling pointer. struct Node { string name; Node* oldestChild; Node* nextYoungerSibling; }; A binary search tree (BST) is empty, or a node with a left binary search tree and a right binary search tree such that the value at every node in the left subtree is &lt;= the value at this node, and the value at every node in the right subtree is &gt;= the value at this node We can search through this tree really quickly (given the tree is relatively balanced). You can guess the value from \\(N\\) items in \\(\\log_2 N\\) guesses. You can also do binary search on an array or vector, but binary trees are faster for insertions and deletion. You can insert and delete here in \\(\\log N\\) time, whereas this operation is linear time in indexable data types. Insertion is a tree algorithm, but you only follow one path so you dont really need recursion. Deleting is easy for a leaf node. Also pretty straightforward for a node with one child. The whole subtree is less than or greater than the deleted nodes parent. Two children that arent empty is tougher. Promote one child to replace the deleted parent. You go left one then as far right as you can go, or one step right and far to the left as you can go. Both are good candidates for the promotion. You keep good performance if the tree stays balanced as you insert and delete. // prints in alphabetical order void printTree(const Node* p) { if (p != nullptr) { printTree(p-&gt;left); cout &lt;&lt; p-&gt; name &lt;&lt; endl; printTree(p-&gt;right); } } This algorithm is neither preorder or postorder. The concept of between makes sense for binary trees (exclusively). New term for this is inorder traversal. How to fill the tree? We know the root must have been the first item inserted. Its children must have been the next. You dont know the exact order of insertion by looking at the final tree. You could get some really bad orderings. If you inserted a sorted list into a BST, you get awful search and other operation efficiency. On average, you get something 6x as long as a perfectly balanced tree. One solution (non-naive insertion) is an AVL tree. At every node, the height of the left and right subtree can differ by no more than one. You keep track of the heights of subtrees, and if an insertion would create an imbalance, you must do a reordering. Its still \\(\\log N\\) for insertion and deletion but with a higher constant of proportionality for rebalancing. Another solution 2-3 Tree. Nodes with 3 children have 2 values, nodes with 2 children have 1 value. Nodes to the right of a 2-value node are less than both values? (there are complicated rules for this). Every leaf node is at the same height. There is more tricky insertion and deletion but we wont get into these details. Still \\(\\log N\\) (even at the worst case) but lower constant of proportionality. Also sometimes \\(\\log_3 N\\). This led into 2-3-4 trees and even higher numbers (because they all reduce height). In a 2-3-4 tree, you can represent direct analogies for 1, 2, 3- value nodes in binary tree form. In order to pull this off you need to store a little bit more binary information for each node about what exact BST analogue it has. Instead of true/false they choose red/black. Thus the BST analogue of a 2-3-4 tree is called a red-black tree. Theres some complicated stuff to transform between the structures. The tree will generally be balanced enough to stay faced. Turns out red-black is faster than 2-3-4 and AVL so most standard libraries use this. CPP library types that do quick lookups: #include &lt;set&gt; set&lt;int&gt; s; s.insert(10); s.insert(30); s.insert(10); //doesn&#39;t insert if (s.find(20) == s.end()) { cout &lt;&lt; &quot;20 is not in the set&quot;; } s.insert(5); for(set&lt;int&gt;::iterator p = s.begin(); p != s.end(); p++) { cout &lt;&lt; *p &lt;&lt; endl; } //will write 5 10 30 s.erase(30); A set will visit items in increasing order. The type of item in the set must have a less than operator (and it must meet the logical mathematical less-than results). Note that you dont need == to use a set. It tells if an item is a duplicate if x &lt;= y and y &lt;= x. So be careful with how you define the less than operator. #include &lt;set&gt; //also same header multiset&lt;int&gt; s; //s allows duplicates, still maintains order "],["week-8-wednesday-hash-tables.html", "19 Week 8 Wednesday: Hash Tables", " 19 Week 8 Wednesday: Hash Tables What if instead of a 100,000 element array of pointers to student records, we used 10,000 buckets with linked lists of elements in them. If we add two elements to the same bucket, this is called a collision. Note: just finding a non-empty bucket does not mean that youve found the specific element youre looking for. Also, no point in sorting the linked lists because you want them to be short anyways in a hash table. Generally, a data structure that can look up efficiently by one index cannot look up quickly by a second index. Also, integers were particularly convenient to index by because you can index and array and get easy bucket numbers. In our student ID example, we need elements to be uniformly distributed but these integers arent, so buckets will be bad (remember that you dont want that many elements per bucket). This is quantified by the load factor, which is the number of items divided by the number of buckets. \\[\\text{load factor} = \\frac{\\text{number of items}}{\\text{number of buckets}}\\] What if we want to make a hashtable with dates? We can just find some integer that maps our dates to 1-10,000. Find an int, then scale down to the number of buckets. This is called a hash function. Heres a hash function for peoples names: add all ASCII character values. But the issue here is that the distribution will not be uniform. One issue is that the hash function only gives values between 0 and 3660. To get bigger numbers, we could multiply (and use unsigned integer so that there is well-defined behavior when you roll over). But multiplying is bad because even one even character code will mean you only use one half of the buckets. (Problems with common factors with the scaling number). One solution is to eliminate common factors. Rather than using 10,000, what if we used a large prime number? That keeps it a bit more uniform. Now we just use a strong hash function that returns nicely distributed integers. A hash function for strings: Variant of FNV-1 (Fowler-Noll-Vo) unsigned int h = 2166136261u; //too big for int constant, so you add u for(char c : theString) { h += c; h += 167777619; } return h; Heres how you use it: #include &lt;functional&gt; using namespace std; string s = &quot;hello&quot;; unsigned int x = std::hash&lt;string&gt;()(s); // overloaded hashObj.operator() "],["week-9-monday-lecture-more-hashtables.html", "20 Week 9 Monday Lecture: More Hashtables 20.1 More STL Data Structures", " 20 Week 9 Monday Lecture: More Hashtables A hash function must: - produce uniformly distributed values - cheap - same key gets same value every time (deterministic) Whats the big O? A hash table with a fixed number of buckets has \\(O(N)\\) for insertion, deletion, finding. So this performs worse than a BST. However, the rate of linear growth is really slow, so \\(N\\) must be really large before it gets worse than \\(O(\\log N)\\). To beat BST, we assume some constant load factor that we never want to exceed (a common choice is 0.75). We increase the number of buckets when an item about to be inserted would put us over the max load factor. Generally, then you make twice as many buckets. Rehash each item and put them into the new range. With fixed maximum load factor, looking things up is a constant time \\(O(1)\\). Insertions will mostly be constant time. Every so often, rehashing is \\(O(N)\\), but this happens rarely and it become rarer and rarer. Over time, this makes insertion constant on average. We can make a small improvement by not rehashing all at once, and generating a new table as we insert. This is called incremental rehashing. Bounded by a lower constant. Area under the curve is the same. 20.1 More STL Data Structures Last time we looked at set and multiset, which both use some sort of Binary Tree to do fairly fast lookup. Now we look at map. #include &lt;map&gt; #include &lt;string&gt; map&lt;string, double&gt; ious; using namespace std; string name; double amt; while (cin &gt;&gt; name &gt;&gt; amt) { ious[name] += amt; } for(map&lt;string, double&gt;::iterator p = ious.begin(); p != ious.end(); p++) cout &lt;&lt; p-&gt;first &lt;&lt; &quot; owes me \\$&quot; &lt;&lt; p-&gt;second &lt;&lt; endl; Uses a std type called pair with a public data member first and second that are of each specified type. Set types have the requirement that you iterate through their elements in increasing order. This doesnt work with a hash table. There are types called unordered_set which doesnt require less than operator, just equality. Then theres no particular order. Also, unordered_multiset, unordered_map, and unordered_multimap. "],["week-9-wednesday-lecture-heaps.html", "21 Week 9 Wednesday Lecture: Heaps", " 21 Week 9 Wednesday Lecture: Heaps This is a data structure where you assign a priority to each item as you put it into a collection, then when you pull out an item you get the highest priority item. A stack or a queue are just specific examples of this structure. There are different conventions about whether high or low numbers have the highest priorities. Well use high numbers to mean high priority in this class. A good data structure for finding elements of highest priority is a BST. Both insertion and removal are \\(O(\\log N)\\). Because we always pull from the right most side, we unbalance our tree. So we can do better. A complete binary tree is filled at ever level, except possibly the deepest level, which is filled from left to right. There is only one unique complete tree for each number of nodes. A (max) heap is a complete binary tree in which the value at every node is greater than the values of all the nodes in its subtrees. A min heap is a complete binary tree in which the value at every node is less than the values of all the nodes in its subtrees. Theres no requirement that left and right children have any relation to each other. When you remove from the heap, you take the root away. The algorithm for restoring the heap property has two parts: 1. Remake the binary tree 2. Restore the heap property To remake the binary tree, you promote a node at the bottom right to the root. Then you trickle down the lower value by swapping parents with their max child until the parent is greater than both their children. Thus, removing an element is worst case \\(O(\\log N)\\) (with a better constant of proportionality than a binary tree). Inserting an element: 1. Add to the right spot to make it a complete binary tree 2. Then compare it to its parent and bubble it up until its smaller. Now heres a structure that can find its bottom right element in constant time. You can represent the heap as an array if you go through amd number each element of the tree by level left to right. How do you preserve parent-child relations? Theres a function that maps child to parent indexes. \\[\\operatorname{parent}(i) = \\left\\lfloor \\frac{i-1}{2} \\right\\rfloor\\] We can also find a function for children: \\[\\operatorname{children}(i) = 2j+1, 2j+2 \\quad \\text{(if they&#39;re in the tree)}\\] Now we dont have a tree, we can do everything with the array. You can also sort items by putting them all into a heap and pull them out one by one. This is called heapsort and it has \\(O(\\log N!) \\approx O(N\\log N)\\). Heapsort algorithm: 1. Make the array into a heap 2. Repeatedly remove items from the heap For step 1, work you way backwards, making everything into a heap. Trickling up with a similar algorithm to how you removed items. Step 1 is the complexity \\(O(N\\log N)\\). Although weve put the large values in the front of the array, were still sorting in increasing order. Now you swap across an imaginary barrier where everything to the right is sorted. Your heap shrinks in the left part of the array. You use the standard removal algorithm. When youre down to 2 items, just swap them if theyre in the wrong order, otherwise youre done. This step is also \\(O(N\\log N)\\). Quicksort still has a better constant of proportionality on average, but a bad worst case. Typically introsort uses quicksort and then heapsort if it gets too deep. "]]
